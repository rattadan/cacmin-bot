# Prometheus alerting rules for Litestream replication monitoring
# Add to your Prometheus rules directory (e.g., /etc/prometheus/rules/litestream.yml)

groups:
  - name: litestream
    interval: 30s
    rules:
      # Alert if Litestream metrics endpoint is down
      - alert: LitestreamDown
        expr: up{job="litestream"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Litestream is down"
          description: "Litestream metrics endpoint has been unreachable for 2 minutes on {{ $labels.instance }}"

      # Alert if sync errors are occurring
      - alert: LitestreamSyncErrors
        expr: increase(litestream_db_sync_error_n[5m]) > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Litestream sync errors detected"
          description: "{{ $value }} sync errors in the last 5 minutes for database {{ $labels.db }}"

      # Alert if no syncs have happened recently (replication stalled)
      - alert: LitestreamReplicationStalled
        expr: increase(litestream_db_sync_n[5m]) == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Litestream replication stalled"
          description: "No sync operations in the last 5 minutes for database {{ $labels.db }}"

      # Alert if checkpoint errors are occurring
      - alert: LitestreamCheckpointErrors
        expr: increase(litestream_db_checkpoint_error_n[15m]) > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Litestream checkpoint errors"
          description: "{{ $value }} checkpoint errors in the last 15 minutes for database {{ $labels.db }}"

      # Alert if WAL file is growing too large (possible checkpoint issues)
      - alert: LitestreamWALTooLarge
        expr: litestream_db_wal_size > 100 * 1024 * 1024  # 100MB
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Litestream WAL file too large"
          description: "WAL size is {{ $value | humanize1024 }}B for database {{ $labels.db }}, checkpointing may be blocked"

      # Alert if shadow WAL is significantly behind (replication lag)
      - alert: LitestreamReplicationLag
        expr: (litestream_db_wal_size - litestream_db_shadow_wal_size) > 10 * 1024 * 1024  # 10MB behind
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Litestream replication lag detected"
          description: "Shadow WAL is {{ $value | humanize1024 }}B behind main WAL for database {{ $labels.db }}"

      # Critical: No sync activity for extended period
      - alert: LitestreamReplicationDead
        expr: increase(litestream_db_sync_n[15m]) == 0
        for: 15m
        labels:
          severity: critical
        annotations:
          summary: "Litestream replication appears dead"
          description: "No sync operations for 15+ minutes for database {{ $labels.db }}. Immediate investigation required."

      # Alert on high sync latency
      - alert: LitestreamSlowSync
        expr: rate(litestream_db_sync_seconds[5m]) / rate(litestream_db_sync_n[5m]) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Litestream sync operations are slow"
          description: "Average sync time is {{ $value | printf \"%.2f\" }}s for database {{ $labels.db }}"
